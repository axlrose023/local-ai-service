# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RAG-—Å–∏—Å—Ç–µ–º—ã

## –û–±—â–∞—è —Å—Ö–µ–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```mermaid
graph TD
    subgraph "üë§ User Layer"
        User((–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å))
    end

    subgraph "üñ•Ô∏è Presentation Layer"
        Chainlit[app.py<br/>Chainlit UI]
    end

    subgraph "üß† Logic Layer"
        Router[router.py<br/>–ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–æ—É—Ç–µ—Ä]
        RAG[rag.py<br/>RAG Service]
        LLM[llm.py<br/>LLM Client]
    end

    subgraph "üîß Shared Services"
        Embedder[embeddings.py<br/>Shared Embedder]
        Config[config.py<br/>Settings]
        ChromaClient[chroma_client.py<br/>HTTP Client]
    end

    subgraph "üíæ Data Layer"
        ChromaDB[(ChromaDB<br/>Vector Store)]
        Ollama[(Ollama<br/>LLM Server)]
        Docs[docs/<br/>PDF, DOCX, TXT]
    end

    subgraph "üîÑ Offline Pipeline"
        Ingest[ingest.py<br/>Document Indexer]
    end

    User --> Chainlit
    Chainlit --> Router
    Chainlit --> RAG
    Chainlit --> LLM

    Router --> Embedder
    RAG --> Embedder
    RAG --> ChromaClient
    Ingest --> Embedder
    Ingest --> ChromaClient

    ChromaClient --> ChromaDB
    LLM --> Ollama
    Ingest --> Docs

    Config -.-> Router
    Config -.-> RAG
    Config -.-> LLM
    Config -.-> Ingest
```

## –ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ (Request Flow)

```mermaid
sequenceDiagram
    autonumber
    participant U as üë§ User
    participant A as üñ•Ô∏è app.py
    participant R as üîÄ router.py
    participant E as üß† embeddings.py
    participant RAG as üîç rag.py
    participant C as üóÑÔ∏è ChromaDB
    participant L as ü§ñ llm.py
    participant O as ü¶ô Ollama

    U->>A: "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å VPN?"
    A->>R: should_search(query)

    Note over R: 1. Skip patterns? ‚ùå<br/>2. Keywords? ‚úÖ "vpn"
    R-->>A: True (–∏—Å–∫–∞—Ç—å)

    A->>RAG: search(query)
    RAG->>E: encode(query)
    E-->>RAG: vector [768]
    RAG->>C: query(vector, top_k=5)
    C-->>RAG: 5 chunks + scores

    Note over RAG: –§–∏–ª—å—Ç—Ä: score > 0.45
    RAG-->>A: 3 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞

    A->>L: chat_stream(query, context, history)
    L->>O: POST /v1/chat/completions

    loop Streaming
        O-->>L: token
        L-->>A: token
        A-->>U: token
    end

    A-->>U: –û—Ç–≤–µ—Ç + –ò—Å—Ç–æ—á–Ω–∏–∫–∏
```

## Fast Flow (–±–µ–∑ RAG)

```mermaid
sequenceDiagram
    autonumber
    participant U as üë§ User
    participant A as üñ•Ô∏è app.py
    participant R as üîÄ router.py
    participant L as ü§ñ llm.py
    participant O as ü¶ô Ollama

    U->>A: "–ü—Ä–∏–≤–µ—Ç!"
    A->>R: should_search("–ü—Ä–∏–≤–µ—Ç!")

    Note over R: Skip pattern: "–ø—Ä–∏–≤–µ—Ç" ‚úÖ
    R-->>A: False (–Ω–µ –∏—Å–∫–∞—Ç—å)

    Note over A: RAG –ø—Ä–æ–ø—É—â–µ–Ω<br/>context = ""

    A->>L: chat_stream(query, "", history)
    L->>O: POST /v1/chat/completions
    O-->>L: stream
    L-->>A: stream
    A-->>U: "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
```

## –õ–æ–≥–∏–∫–∞ —Ä–æ—É—Ç–µ—Ä–∞ (3-Stage Decision)

```mermaid
flowchart TD
    Start([–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è]) --> Len{len < 3?}
    Len -->|–î–∞| NoSearch[‚ùå –ù–ï –ò–°–ö–ê–¢–¨]
    Len -->|–ù–µ—Ç| Skip

    subgraph "Stage 1: Skip Patterns (0ms)"
        Skip{–°–æ–¥–µ—Ä–∂–∏—Ç<br/>'–ø—Ä–∏–≤–µ—Ç', '—Å–ø–∞—Å–∏–±–æ'...?}
    end
    Skip -->|–î–∞| NoSearch
    Skip -->|–ù–µ—Ç| Keywords

    subgraph "Stage 2: Keywords (0ms)"
        Keywords{–°–æ–¥–µ—Ä–∂–∏—Ç<br/>'vpn', '–æ—Ç–ø—É—Å–∫'...?}
    end
    Keywords -->|–î–∞| Search[‚úÖ –ò–°–ö–ê–¢–¨]
    Keywords -->|–ù–µ—Ç| Semantic

    subgraph "Stage 3: Semantic (~20ms)"
        Semantic[Cosine similarity<br/>—Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏]
        Semantic --> Threshold{score > 0.35?}
    end
    Threshold -->|–î–∞| Search
    Threshold -->|–ù–µ—Ç| NoSearch

    Search --> RAG[–ó–∞–ø—É—Å–∫ RAG Pipeline]
    NoSearch --> LLM[–ü—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç LLM]
```

## Pipeline –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

```mermaid
flowchart LR
    subgraph "üìÅ Input"
        PDF[PDF]
        DOCX[DOCX]
        TXT[TXT/MD]
    end

    subgraph "üîÑ ingest.py"
        Extract[extract_text]
        Chunk[chunk_text<br/>500 chars, 50 overlap]
        Hash[MD5 hash<br/>–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è]
        Embed[embedder.encode<br/>batch=50]
    end

    subgraph "üíæ Output"
        Chroma[(ChromaDB)]
    end

    PDF --> Extract
    DOCX --> Extract
    TXT --> Extract
    Extract --> Chunk
    Chunk --> Hash
    Hash -->|–Ω–æ–≤—ã–π/–∏–∑–º–µ–Ω—ë–Ω| Embed
    Hash -->|–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π| Skip[‚è≠Ô∏è Skip]
    Embed --> Chroma
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ ChromaDB

```mermaid
erDiagram
    COLLECTION ||--o{ DOCUMENT : contains

    COLLECTION {
        string id PK
        string name "corporate_docs"
        json metadata "hnsw:space=cosine"
    }

    DOCUMENT {
        string id PK "filename_hash_index"
        float[] embedding "768 dimensions"
        string content "chunk text"
        string source "filename.pdf"
        string file_path "/path/to/file"
        string file_hash "md5"
        int chunk_index "0, 1, 2..."
    }
```

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏

```mermaid
graph BT
    subgraph "Core"
        config[config.py]
        embeddings[embeddings.py]
        chroma[chroma_client.py]
    end

    subgraph "Services"
        router[router.py]
        rag[rag.py]
        llm[llm.py]
        ingest[ingest.py]
    end

    subgraph "App"
        app[app.py]
    end

    config --> embeddings
    config --> chroma
    config --> router
    config --> rag
    config --> llm
    config --> ingest

    embeddings --> router
    embeddings --> rag
    embeddings --> ingest

    chroma --> rag
    chroma --> ingest

    router --> app
    rag --> app
    llm --> app
```

## –ü–æ—Ä—Ç—ã –∏ —Å–µ—Ä–≤–∏—Å—ã

| –°–µ—Ä–≤–∏—Å | –ü–æ—Ä—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|--------|------|------------|
| Chainlit | 8000 | Web UI |
| ChromaDB | 8001 | Vector Database |
| Ollama | 11434 | LLM Inference |

## –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env)

```
CHROMA_HOST=localhost
CHROMA_PORT=8001
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=qwen2.5:7b
```
